[[ch02-Architecture]]
== CockroachDB Architecture

The architecture of a software system defines the high-level design decisions that enable the goals of that system.   As you may recall from <<ch01-introduction>>, the goals of CockroachDB are to provide a scalable, highly available, highly performant, strongly consistent, geo-distributed, SQL-powered relational database system capable of running across a wide variety of hardware platforms.  The architecture of CockroachDB is aligned to those objectives.

.Feel Free to Skip Ahead!
****
The CockroachDB architecture is sophisticated:  it incorporates decades of database engineering best practice designs together with several unique innovations.  However, CockroachDB doesn't require that you understand its internals to get things done.   If you're in a hurry to get started with CockroachDB, you can skip forward to the next chapter and return to this chapter later as necessary.   We will, however, assume you are broadly familiar with the key concepts in this chapter when we consider advanced topics later in the book.  Those key concepts are summarized over the next few pages and elaborated on in the remainder of the chapter.
****

There are multiple ways of looking at the CockroachDB architecture.  At the cluster level, a CockroachDB deployment consists of one or more shared-nothing, leaderless nodes that collaborate to present a single logical view of the distributed database system.  Within each node, we can observe the CockroachDB architecture as a series of layers that provide essential database services, including SQL processing, transaction processing, replication, distribution, and storage.  


In this chapter, we'll endeavor to give you a comprehensive overview of the CockroachDB architecture.  The aim of the chapter is to provide you with the [.keep-together]#fundamental# concepts that will help you make sensible decisions regarding schema design, performance optimization, cluster deployment, and other topics. 

=== The CockroachDB Cluster Architecture

From a distance, a CockroachDB deployment consists ((("cluster architecture", "nodes")))((("architecture", see="cluster architecture")))((("nodes")))of one or more database server processes.  Each server has its own dedicated storage—the familiar "shared-nothing" database cluster pattern.  The nodes in a CockroachDB cluster are symmetrical—there are no "special" or "primary" nodes.  This storage is often directly attached to the machine on which the CockroachDB server runs, though it's also possible for that data to be physically located on a shared storage subsystem.
Data is distributed across the ((("cluster architecture", "key ranges")))((("key ranges")))cluster based on _key ranges_.  Each range is replicated to at least three members of the cluster.

__Database clients__—applications, administrative consoles, the CockroachDB shell, and so on—connect to a CockroachDB server ((("cluster architecture", "database clients")))((("databases", "clients")))within the cluster.

The communications between a database server ((("cluster architecture", "wire protocol (PostgreSQL)")))((("PostgreSQL", "wire protocol")))and database client occur over the PostgreSQL _wire protocol_ format.  This protocol describes how SQL requests and responses are transmitted between a PostgreSQL client and a PostgreSQL server.  Because CockroachDB uses the PostgreSQL wire protocol, any PostgreSQL driver can be used to communicate with a CockroachDB server.
In a more complex deployment, one or ((("cluster architecture", "load balancer processes")))((("load balancers")))more _load balancer_ processes will be responsible for ensuring that these connections are evenly and sensibly distributed across nodes.   The load balancer will connect the client with one of the nodes within the cluster, which ((("cluster architecture", "gateway servers")))((("gateway servers")))((("servers", "gateway servers")))will become the _gateway server_ for the connection.

The client request might involve reading ((("cluster architecture", "leaseholder nodes")))((("nodes", "leaseholder nodes")))((("leaseholder nodes")))((("nodes", "Raft leader")))((("Raft leader")))and writing data to a single node or to multiple nodes within the cluster.  For any given range of KVs, a _leaseholder node_ will be responsible for controlling reads and writes to that range.  The leaseholder is also usually the _Raft leader_, which has the responsibility to make sure that replicas of the data are maintained correctly.

<<Figure02-01>>  illustrates some of these concepts.  A database client connects to a load balancer (1) that serves as a proxy for the CockroachDB cluster.  The load balancer directs requests to an available CockroachDB node (2).  This node becomes the gateway node for this connection.  The request requires data in range 4, so the gateway node communicates with the leaseholder node for this range (3), which returns data to the gateway, which in turn returns the required data to the database client (4).

 
[[Figure02-01]] 
.CockroachDB cluster architecture
image::images/cdb2_0201.png[CockroachDB Cluster architecture]

This architecture distributes load evenly across the nodes of the cluster. Gateway duties are distributed evenly across the nodes of the cluster by the load balancer; leaseholder duties are similarly distributed by ranges across all the nodes.

If a query requires data from multiple ranges or where data must be changed (and therefore replicated), the workflow involves more steps. We'll examine the nuances of CockroachDB distribution and replication later in this chapter, but for now there are a few concepts we need to understand.

Under the hood, data ((("tables", "KV (key-value) storage system")))((("KV (key-value) storage system")))((("key-value storage system", see="KV storage system")))in a CockroachDB table is organized in a KV storage system.  The key for the KV store is the table's primary key.  The value in the KV store is a binary representation of the values for all the columns in that row.

[role="pagebreak-before"]
Indexes are also stored in the ((("indexes", "KV (key-value) storage system")))((("KV (key-value) storage system", "indexes")))KV system.  In the case of a nonunique index, the key is the index key concatenated to the table's primary key.  In the case of a unique index, the key is the index key, with the primary key appearing as the corresponding value for that key.

_Ranges_ store contiguous ((("ranges")))((("cluster architecture", "ranges")))spans of KVs.   Ranges are analogous to _shards_ or _shard chunks_ in other databases.   <<Figure02-02>>  illustrates how a "dogs" table might be segmented into ranges.

 


[[Figure02-02]] 
.Ranges
image::images/cdb2_0202.png[Ranges]

As mentioned earlier, _leases_ are granted to a ((("nodes", "leases")))((("leases")))node giving it responsibility for managing reads and writes to a range.  The node holding the lease is known as the _leaseholder_.  The same node is generally ((("nodes", "Raft leader")))((("Raft leader")))also the _Raft leader_, which is responsible for ensuring that replicas of the node are correctly maintained across multiple nodes.

=== The CockroachDB Software Stack


Each CockroachDB node runs a copy of the CockroachDB software, which is a single multithreaded process. From the OS perspective, the CockroachDB process might seem like a closed box, but internally it is organized into multiple logical layers, as shown in <<Figure02-03>>.

We'll discuss each of these layers in turn as we proceed through the chapter. 

[[Figure02-03]] 
.CockroachDB software layers
image::images/cdb2_1501.png[Software Layers]



=== The CockroachDB SQL Layer

The SQL layer is the part of the CockroachDB ((("SQL layer", id="sqlyrl")))((("software stack SQL layer", id="sfskqly")))software stack that is responsible for handling SQL requests.  Because CockroachDB is a SQL database, you would be forgiven for thinking that the SQL layer does pretty much everything.  However, the core responsibility of the SQL layer is actually to turn SQL requests into KV operations.  Other layers handle transactions, distribution, and replication of ranges and physical storage to disk.

[role="pagebreak-after"]
The SQL layer receives requests ((("PostgreSQL", "wire protocol")))from database clients over the PostgreSQL wire protocol. A database client is any program that uses a database driver to communicate with the server. It includes the CockroachDB command-line SQL processor, GUI tools such as DBeaver or Tableau, or applications written in Java, Go, Node.js, Python, or any other language that has a compatible driver.

The PostgreSQL wire protocol describes the format of network packets that are used to send requests and receive results from a database client and server.  The wire protocol lays on top of a transport medium such as TCP/IP or Unix-style sockets.  The use of the PostgreSQL wire protocol allows CockroachDB to take advantage of the large ecosystem of compatible language drivers and tools that support the PostgreSQL database.

The SQL layer parses the SQL request, checking it for syntactical accuracy and ensuring that the connection has privileges to perform the requested task.  

CockroachDB then creates an execution plan for the SQL statement and proceeds to _optimize_ that plan.

SQL is a declarative language: you define the data you want, not how to get it. Although the nonprocedural nature of SQL results in improvements in programmer productivity, the database server must support a set of sophisticated algorithms to determine the ((("SQL layer", "optimizer")))optimal method of executing the SQL. These algorithms are collectively referred to as _the optimizer_.

For almost all SQL statements, there will be more than one way for CockroachDB to retrieve the rows required.   For instance, given a SQL statement with `JOIN` and `WHERE` clauses, there may be multiple join orders and multiple access paths (table scans, index lookups, etc.) available to retrieve data. It's the goal of the optimizer to determine the best access path. CockroachDB's SQL optimizer has some unique features relating to its distributed architecture, but broadly speaking, the cost-based optimizer is similar to that found in other SQL databases such as Oracle or PostgreSQL.

The optimizer uses both heuristics—rules—and cost-based algorithms to perform its work.

The first stage of the SQL optimization process is to transform the SQL into a normalized form suitable for further optimization.  This transformation removes any redundancies in the SQL statement and performs rule-based transformations to improve performance.  The transformation takes into account the distribution of data for the table, adding predicates to direct parts of the queries to specific ranges or adding predicates that allow the use of indexed retrieval paths. 

The optimization of the SQL statement proceeds in two stages: expansion and ranking.  The SQL statement is transformed into an initial plan. Then the optimizer expands that plan into a set of equivalent candidate plans that involve alternative execution paths such as join orders or indexes.
The optimizer then ranks the plans by calculating the relative cost of each operation, leveraging statistics that supply the size and distribution of data within each table.  The plan with the lowest cost is then selected. 

CockroachDB also supports a _vectorized execution_ engine ((("vectorized execution")))((("execution, vectorized")))that can speed up the processing of batches of data.  This engine translates data from a row-oriented format (where sets of data contain data from the same row) to a column-oriented format (where every set of data contains ((("SQL layer", startref="sqlyrl")))((("software stack SQL layer", startref="sfskqly")))information from the same column).

We'll return to the optimizer in <<Ch08_SQL_Tuning>> when we look in detail at SQL tuning.

=== From SQL to Key-Values

As we mentioned earlier, CockroachDB data is stored in a KV storage system that is distributed across multiple nodes in ranges. We'll look at the details of this storage system toward the end of the chapter, but since the outputs of the SQL layer are, in fact, KV operations, the mapping of data from tables and indexes to KV representation is part of the SQL layer. The output of the SQL layer are KV operations.

This translation means that only the SQL layer needs to be concerned with SQL syntax—all the subsequent layers are blissfully unaware of the SQL language.

==== Tables as Represented in the KV Store

Each entry in the KV store has a ((("KV (key-value) storage system", "tables")))((("tables", "KV (key-value) storage system")))key based on the following structure:

----
/<tableID>/<indexID>/<IndexKeyValues>/<ColumnFamily>
----

We'll discuss column families in the next section.  By default, all columns are included in a single default column family.

For a base table, the default `indexID` is "primary."

<<Figure02-04>> shows a simplified version of this mapping, omitting the column family identifier.
 
[[Figure02-04]] 
.KV to column mappings
image::images/cdb2_0204.png[Key-Value to column mappings]

<<Figure02-04>> illustrates the table name and index name ("primary") as text, but within the KV store, these are represented as compact table and index identifiers. 

==== Column Families

In the preceding example, all the ((("column families")))((("tables", "column families")))columns for a table are aggregated in the value section of a single KV entry.  However, it's possible to direct CockroachDB to store groups of columns in separate KV entries using column families.  Each column family in a table will be allocated its own KV entry. <<Figure02-05>> depicts this concept—if a table has two column families, then each row in the table will be represented by two KV entries.

[[Figure02-05]]
.Column families in the KV store
image::images/cdb2_0205.png[Column Families in the KV store]

Column families can have a number of advantages.  If infrequently accessed large columns are separated, then they will not be retrieved during row lookups, which can improve the efficiency of the KV store cache. Furthermore, concurrent operations on columns in separate column families will not interfere with each other.

==== Indexes in the KV Store

Indexes are represented by ((("KV (key-value) storage system", "indexes")))((("indexes")))a similar KV structure.  For instance, the representation of a nonunique index is shown in <<Figure02-06>>.
 
[[Figure02-06]] 
.Nonunique index KV store representation
image::images/cdb2_0206.png[Non-unique index KV store representation]

The key for a nonunique index includes the table and index name, the KV, and the primary KV. For a nonunique index, there is no "value" by default.

For a unique index, the KV value defaults to the value of the primary key.  So, if +name+ was unique in the +inventory+ table used in previous examples, a unique index on +name+ is represented as in <<Figure02-07>>.
 
[[Figure02-07]] 
.Unique index KV store representation
image::images/cdb2_0207.png[Unique index KV store representation]

==== Inverted Indexes

CockroachDB columns can be ((("KV (key-value) storage system", "indexes", "inverted indexes")))((("indexes", "inverted")))((("inverted indexes")))defined as arrays or JSON documents. We'll discuss this in detail in <<Ch04_CockroachDB_SQL>>.

Inverted indexes allow indexed searches into values included in these arrays or JSON documents.  In this case, the KVs include the JSON path and value together with the primary key, as shown in <<Figure02-08>>.
 
[[Figure02-08]] 
.Inverted index KV representation
image::images/cdb2_0208.png[Inverted Index KV representation]

Inverted indexes are also used on spatial data.

Inverted indexes can be larger and more expensive to maintain than other indexes because a single JSON document in a row will generate one index entry for each unique attribute.  For complex JSON documents, this might result in dozens of index entries for each document. We'll also discuss this further—and consider some alternatives—in <<Ch08_SQL_Tuning>>.

==== The STORING Clause

The +STORING+ clause of `CREATE INDEX` allows us to add additional columns to the value portion of ((("KV (key-value) storage system", "indexes", "STORING clause")))((("indexes", "STORING clause")))((("columns", "STORING clause")))the KV index structure.  These additional columns can streamline a query that contains a projection (e.g., a `SELECT` list) that includes only those columns and the index keys.  For instance, in <<Figure02-09>>, we see a nonunique index on `name` and `dateOfBirth` that uses the `STORING` clause to add the phone number to the KV value.  Queries that seek to find the phone number using name and date of birth can now be resolved by the index alone without reference to the base table.

[[Figure02-09]] 
.`STORING` clause of `CREATE INDEX`
image::images/cdb2_0209.png[STORING clause of CREATE INDEX]

==== Table Definitions and Schema Changes

The schema definitions for tables (and their associated indexes) ((("tables", "schema changes")))((("schemas", "table descriptor")))((("table descriptor")))are stored in a special keyspace called a _table descriptor_.  For performance reasons, table descriptors are replicated on every node.  The table descriptor is used to parse and optimize SQL and to correctly construct KV operations for a table.

CockroachDB supports online schema changes using `ALTER TABLE`, `CREATE INDEX`, and other commands.  The schema is changed in discrete stages that allow the new schema to be rolled out while the previous version is still in use.   Schema changes run as background tasks.

The node initiating the schema ((("nodes", "schema changes")))change will acquire a write lease on the relevant table descriptor.  Nodes that are performing data manipulation language (DML) on a table will ((("DML (data manipulation language)")))((("data manipulation language", see="DML")))have a lease on the relevant table descriptor.  When the node holding the write lease modifies the definition, it is broadcast to all nodes in the cluster that will—when it becomes possible—release their lease on the old schema.

The schema change may involve changes to table data (removing or adding columns) and/or creating new index structures.    When all of the instances of the table are stored according to the requirements of the new schema, then all nodes will switch over to the new schema and will allow reads and writes of the table using the new schema.

[[cockroachDB_transaction_layer]]
=== The CockroachDB Transaction Layer

The transaction layer is responsible ((("transaction layer")))for maintaining the atomicity of transactions by ensuring that all operations in a transaction are committed or aborted.

Additionally, the transaction layer maintains&mdash;by default&mdash;serializable isolation ((("transactions", "serializable isolation")))((("serializable isolation")))((("isolation", "serializable isolation")))between transactions; this means that transactions are completely isolated from the effects of other transactions.  Although multiple transactions may be in progress at the same time, the experience of each transaction is as if the transactions were run one at a time—the _serializable_ isolation level.

.Isolation Levels
****
Transaction "isolation levels" define to ((("isolation levels")))((("transactions", "isolation levels")))((("READ UNCOMMITTED isolation level")))((("READ COMMITTED isolation level")))((("REPEATABLE READ isolation level")))((("SERIALIZABLE isolation level")))what extent transactions are isolated from the effects of other transactions.  ANSI SQL defines four isolation levels that are, from weakest to strongest: `READ UNCOMMITTED`, `READ COMMITTED`, `REPEATABLE READ`, and `SERIALIZABLE`.  Additionally, an isolation level of `SNAPSHOT` is used by many databases as an alternative "strong" isolation level.

The majority of relational databases use a default isolation level of `READ COMMITTED`, allowing for improved concurrency at the expense of consistency. CockroachDB supports both `SERIALIZABLE` and `READ COMMITTED`, with `SERIALIZABLE` being the default isolation level. 

When using the default `SERIALIZABLE` isolation level, CockroachDB transactions must exhibit absolute independence from all other transactions.  The results of a set of concurrent transactions must be the same as if they had all been performed one after the other.

For applications designed for `READ COMMITTED` isolation, CockroachDB allows operators to lower the default isolation to `READ COMMITTED` for a more streamlined migration to CockroachDB.
****

[role="pagebreak-before"]
The transaction layer processes KV operations generated by the SQL layer.  A transaction consists of multiple KV operations, some of which may be the result of a single SQL statement.  In addition to updating table entries, index entries must also be updated.  Maintaining perfect consistency under all circumstances involves multiple sophisticated algorithms, not all of which can be covered in this chapter.  For comprehensive information, you may wish to consult the https://cockroa.ch/3rKVaJX[CockroachDB 2020 SIGMOD paper], which covers many of these principles in more detail.

[[MVCC_principles]]
==== MVCC Principles

Like most transactional database ((("transaction layer", "MVCC principles")))((("MVCC (multiversion concurrency control)")))systems, CockroachDB implements the multiversion concurrency control (MVCC) pattern.  MVCC allows readers to obtain a consistent view of information, even while that information is being modified.  Without MVCC,  consistent reads of a data item need to block (typically using a "read lock") simultaneous writes of that item and vice versa.  With MVCC, readers can obtain a consistent view of information even while the information is being modified by a concurrent transaction.

<<Figure02-10>> illustrates the basic principles of MVCC.  At time t1, session s1 reads from row r2 and accesses version v1 of that row (1).    At timestamp t2, another database session, s2, updates the row (2), creating version v2 of that row (3).  At t3, session s1 reads the row again, but—because s2 has not yet committed its change—continues to read from version v1 (4).  After s2 commits (5), session s1 issues another select and now reads from the new v2 version of the row (6).

The CockroachDB implementation limits the ability of transactions to read from previous versions.  For instance, if a read transaction commences after a write transaction has begun, it may not be able to read the original version of the row because it might be inconsistent with other data already read or that will be read later in the transaction. This may result in the read transaction "blocking" until the write transaction commits or aborts.

We'll see later on how the storage engine implements MVCC, but for now, the important concept is that multiple versions of any row are maintained by the system, and transactions can determine which version of the row to read depending on their timestamp and the timestamp of any concurrent transactions.

[[Figure02-10]] 
.MVCC
image::images/cdb2_0210.png[MultiVersion Consistency Control (MVCC)]

==== Transaction Workflow

Distributed transactions must proceed ((("transaction layer", "transaction workflow")))in multiple stages.  Simplistically, each node in the distributed system must lay the groundwork for the transaction and the transaction will be finalized only if all nodes report that the transaction can be performed.

<<Figure02-11>> illustrates a highly simplified flow of transaction preparation.  In this case, a two-statement transaction is sent to the CockroachDB gateway node (1).  The first statement involves a change to range 2, so that request is sent to the leaseholder for that range (2), which creates a new tentative version of the row and propagates changes to replica nodes (3 and 4).     The second statement affects range 4, so the transaction coordinator sends that request to the appropriate leaseholder (5), which is also propagated (6 and 7).  When all changes have correctly propagated, the transaction completes, and the client is notified of success (8).

 
[[Figure02-11]] 
.Basic transaction flow
image::images/cdb2_0211.png[Basic transaction Flow]

 
==== Write Intents

During the initial stages of transaction ((("transaction layer", "write intents")))((("write intents")))processing, when it is not yet known whether the transaction will succeed, the leaseholder writes tentative modifications to modified values known as _write intents_.  Write intents are specially constructed MVCC-compliant versions of the records, which are marked as provisional.  They serve both as tentative transaction outcomes and as locks that prevent any concurrent attempts to update the same record.

[role="pagebreak-before"]
Inside the first key range to be ((("transaction records")))modified by the transaction, CockroachDB writes a special _transaction record_.  This records the definitive status of the transaction.  In the example shown in <<Figure02-11>>, this transaction record would be stored in range 2 because that is the first range to be modified in the transaction.

This transaction record will record the transaction state as one of the following:

`PENDING`:: Indicates that the write intent's transaction is still in
progress.
`STAGING`:: All transaction writes have been performed, but the
transaction is not yet guaranteed to commit.
`COMMITTED`:: The transaction has been successfully completed.
`ABORTED`:: Indicates that the transaction was aborted and its values should be discarded.

==== Parallel Commits

In a distributed database, the number of ((("transaction layer", "Parallel Commits", id="trprcm")))((("Parallel Commits", id="prllcmm")))network round trips is often the dominant factor in latency. In general, committing a distributed transaction requires at least two round trips (indeed, one of the classic algorithms for this is called Two-Phase Commit). CockroachDB uses an innovative protocol called _Parallel Commits_ to hide one of these round trips from the latency as perceived by the client.

The key insight behind Parallel Commits is that the gateway can return success to the client as soon as it becomes impossible for the transaction to abort, even if it is not yet fully committed. The remaining work can be done after returning as long as its outcome is certain. This is done by transitioning the transaction to the `STAGING` state ((("STAGING transactions")))((("transactions", "STAGING transactions")))in parallel with the transaction's last round of writes. The keys of all of these writes are recorded in the transaction record. A `STAGING` transaction must be committed if and only if all of those writes succeed.

[role="pagebreak-after"]
Usually, the gateway learns the status of these writes as soon as they are complete and returns control to the client before beginning the final resolution of the transaction in the background. If the gateway fails, the next node to encounter the `STAGING` transaction record is responsible for querying the status of each write and determining whether the transaction must be committed or aborted (but because the transaction record and each write intent have been written durably, the outcome is guaranteed to be the same whether the transaction is resolved by its original gateway or by another node).

Note that any locks held by the transaction are not released until after this resolution process has been completed. Therefore, the duration of a transaction from the perspective of another transaction waiting for its locks is still at least two round trips (just as in Two-Phase Commit). However, from the point of view of the session issuing ((("transaction layer", "Parallel Commits", startref="trprcm")))((("Parallel Commits", startref="prllcmm")))the transaction, the elapsed time is significantly reduced.

==== Transaction Cleanup

As discussed in the previous ((("transaction layer", "transaction cleanup")))section, a `COMMIT` operation "flips a switch" in the transaction record to mark the transaction as committed, minimizing any delays that would otherwise occur when a transaction is committed.  After the transaction has reached the `COMMIT` stage, then it will asynchronously resolve the write intents by modifying them into normal MVCC records representing the new record values.

However, as with any asynchronous operation, there may be a delay in performing this cleanup. Furthermore, since a committed write intent looks the same as a pending write intent, transactions that encounter a write intent record when reading a key will need to determine if the write intent is committed.

If another transaction encounters a write intent that has not yet been cleaned up by the transaction coordinator, then it can perform the write intent cleanup by checking the transaction record.  The write intent contains a pointer to the transaction records, which can reveal if the transaction is committed. 

==== Overview of Transaction Flow

<<Figure02-12>> illustrates the flow of a successful ((("transaction layer", "transaction flow", id="trscflw")))two-statement transaction.  A client issues an `UPDATE` statement (1).  This creates a transaction coordinator that maintains a transaction record in `PENDING` state.  Write intent commands are issued to the leaseholder for the range concerned (2).  The leaseholder writes the intent markers to its copy of the data.  It returns success to the transaction coordinator without waiting for the replica's intents to be acknowledged.

Subsequent modifications in the transaction are processed in the same manner.  

The client issues a `COMMIT` (3).  The transaction coordinator marks the transaction status as `STAGING`. When all write intents are confirmed, the initiating client is advised of success, and then the transaction status is set to `COMMITTED` (4).

After a successful commit, the transaction coordinator resolves the write intents in affected ranges, which become normal MVCC records (5). At this point, the transaction has released all its locks, and other transactions on the same records are free to proceed.

 
[[Figure02-12]] 
.Transaction sequence
image::images/cdb2_0212.png[Transaction sequence]

<<Figure02-12>> is highly simplified but can still be a little hard to unpack.   There are two main takeaways from the diagram:

* Most operations respond in two stages; we can proceed to the next step after the first response and need to resolve everything only at the end of the commit.

* The latency for the client doesn't include all of the cleanup operations.   The `UPDATE` operations return before all the write intents are propagated, and the [.keep-together]#`COMMIT`# returns before all the write intents are resolved. Hopefully, this removes a lot of the ((("transaction layer", "transaction flow", startref="trscflw")))overhead of distributed database management from application response time.

==== Read/Write Conflicts

So far, we've looked at the processing of ((("transaction layer", "read/write conflicts", id="trswwfl")))((("read/write conflicts", id="rwrflc")))successful transactions.  It would be great if all transactions succeeded, but in all but the most trivial scenarios, concurrent transactions create conflicts that must be resolved.

The most obvious case is when two transactions attempt to update the same record.  There cannot be two write intents active against the same key, so one of the transactions will wait for the other to complete, or one of the transactions will be aborted.  If the transactions are of the same priority, then the second transaction—the one that has not yet created a write intent—will wait.  However, if the second transaction has a higher priority, then the original transaction will be aborted and will have to retry.

Transaction priorities can be ((("transactions", "priorities")))adjusted with the `SET TRANSACTION` statement—see <<Ch06_Application_design_and_implementation>>.

Transaction isolation levels can be set ((("transactions", "isolation levels", "per-transaction setting")))((("isolation levels")))on a per-transaction basis with the `BEGIN TRANSACTION ISOLATION LEVEL READ COMMITTED` statement or by setting defaults at the database or role level as follows:

[source, sql]
----
-- Database level.
ALTER DATABASE your_db SET default_transaction_isolation = 'read committed';

-- Role level.
ALTER ROLE your_role SET default_transaction_isolation = 'read committed';
----

The +TxnWaitQueue+ object tracks the transactions that are waiting and the transactions that they are waiting on.  This structure is maintained within the Raft leader of the range associated with the transaction.  When a transaction commits or aborts, the +TxnWaitQueue+ is updated, and any waiting transactions are notified.

A _deadlock_ can occur if two ((("transactions", "deadlocks")))((("deadlocks")))transactions are both waiting on write intents created by the other transaction.  In this case, one of the transactions will be randomly aborted. We'll discuss this in more detail in <<Ch06_Application_design_and_implementation>>.

Transaction conflicts can also occur between readers and writers.  If a reader encounters an uncommitted write intent that has a lower (i.e., earlier) timestamp than the consistent read timestamp for the read, then a consistent read cannot be completed. This can happen if a modification occurs between the time a read transaction starts and the time it attempts to read the key concerned.  In this case, the ((("transactions", "blocked reads")))read will need to wait until the write either commits or aborts.

[role="pagebreak-before"]
These “blocked reads” can be avoided in the following circumstances: 

*  If the read has a high priority, CockroachDB may "push" the lower-priority write's timestamp to a higher value, allowing the read to complete.  The "pushed" transaction may need to restart if the push invalidates any previous work in the transaction.

* Stale reads that use `AS OF SYSTEM TIME` will not block (as long as the transaction does not exceed the specified staleness).  We’ll discuss `AS OF SYSTEM TIME` a bit later in this chapter.

* In multiregion configurations—which we’ll describe in detail in <<Ch11_Multiregion_deployment>>—++GLOBAL++ tables use a modified transaction protocol in which reads are not blocked by writes.

Many transaction conflicts are managed automatically, and while these have performance implications, they don't impact functionality or code design.  However, there are multiple scenarios in which an application may need to handle an aborted transaction. We'll look at ((("transaction layer", "read/write conflicts", startref="trswwfl")))((("read/write conflicts", startref="rwrflc")))these scenarios and discuss best practices for transaction retries in <<Ch06_Application_design_and_implementation>>.

==== Clock Synchronization and Clock Skew

You may have noticed in previous sections ((("transaction layer", "system clock", id="tryrsys")))((("timestamps", "system clock time", id="tmmpck")))((("system clock", "synchronization", id="syckyz")))((("system clock", "skew", id="sysckkw")))((("clock skew", id="clckkw")))that CockroachDB must compare timestamps of operations frequently to determine if a transaction is in conflict.   Simplistically, we might imagine that every node in the system can agree on the time of each operation and make these comparisons easily.  In reality, every system is likely to have a slightly different system clock time, and this discrepancy is likely to be greater the more geographically distributed a system is.  The difference in clock times is referred to as _clock skew_. Consequently, in widely distributed systems with very high transaction rates, getting nodes to agree on the exact sequence of transactions is problematic.
As you might remember, Spanner attacked this problem by using specialized hardware—atomic clocks and GPS—to reduce the inconsistency between system clocks. As a result, Spanner can keep the clock skew within 7 ms and simply adds a 7 ms sleep to every transaction to ensure that no transactions complete out of order.

Since CockroachDB must run reliably on generic hardware, it synchronizes time using the venerable and ubiquitous internet Network Time Protocol (NTP).  NTP produces accurate timestamps but nowhere near as accurate as Spanner's GPS and atomic clocks.

By default, CockroachDB will tolerate a clock skew as high as 500 ms.  Adding half a second to every transaction in the Spanner manner would be untenable, so CockroachDB takes a different approach for dealing with transactions that appear within the 500 ms uncertainty interval.   Put simply, while Spanner always waits after writes, CockroachDB sometimes retries reads.

If a reader can't say for certain whether a value being read was committed before the read transaction started, then it pushes its own provisional timestamp just above the timestamp of the uncertain value.   Transactions reading constantly updated data from many nodes may be forced to restart multiple times, though never for longer than the uncertainty interval, nor more than once per node.

The CockroachDB time synchronization strategy allows CockroachDB to deliver true serializable consistency.  However, there are still some anomalies that can occur.  Two transactions that operate on unrelated KVs that still have some real-world sequencing dependency might appear to be committed in reverse order—the _causal reverse_ anomaly.   This is not a violation of serializable isolation because the transactions are not actually logically dependent.  Nevertheless, it is possible ((("timestamps", "system clock time", startref="tmmpck")))((("system clock", "synchronization", startref="syckyz")))((("system clock", "skew", startref="sysckkw")))((("clock skew", startref="clckkw")))((("transaction layer", "system clock", startref="tryrsys")))in CockroachDB for transactions to have timestamps that do not reflect their real-world ordering.

=== The CockroachDB Distribution Layer

Logically, a table is represented in CockroachDB as a monolithic KV structure, in which the key is a concatenation of the primary keys of the table, and the value is a concatenation of all of the remaining columns in the table.   We introduced this structure back in <<Figure02-02>>.

The distribution layer breaks this monolithic structure into contiguous chunks of approximately 512 MB.  The 512 MB chunk is sized to keep the number of ranges per node manageable.
The distribution layer keeps data distributed evenly across the cluster while simultaneously presenting a unified and consolidated view of that data to the applications that need it.  

==== Meta Ranges 

The distribution of ranges is stored ((("distribution layer", "meta ranges")))((("meta ranges")))in global keyspaces +meta1+ and +meta2+.  +meta1+ can be thought of as a "range of ranges" lookup, which then allows a node to find the location of the node holding the +meta2+ record, which in turn points to the nodes holding copies of every range within the "range of ranges."  <<Figure02-13>> illustrates this two-level lookup structure.

Node 1 needs to get data for the key "HarrisonGuy."  It looks in its copy of +meta1+, which tells it that node2 contains the +meta2+ information for the range G–M.  It accesses the +meta2+ data concerned from node 2, which indicates that node4 is the leaseholder for the range G–I, and therefore the leaseholder for the range concerned.

[[Figure02-13]] 
.Meta ranges
image::images/cdb2_0213.png[Meta Ranges]

==== Gossip

CockroachDB uses the _gossip_ protocol to share ((("distribution layer", "gossip protocol")))((("gossip protocol")))ephemeral information between nodes.  Gossip is a widely used protocol in distributed systems in which nodes propagate information virally through the network.

Gossip maintains an eventually consistent KV map on all the CockroachDB nodes. It is used primarily for bootstrapping: it contains a "meta0" record that tells the cluster where the `meta1` range can be found, as well as mappings from the node IDs stored in meta records to network addresses. Gossip is also used for certain operations that do not require strong consistency, such as maintaining information about the available storage space on each node for rebalancing purposes.

==== Leaseholders

The leaseholder is the CockroachDB node ((("distribution layer", "leaseholders")))((("leaseholder nodes")))responsible for serving reads and coordinating writes for a specific range of keys.  We discussed some of the responsibilities of the leaseholder in <<cockroachDB_transaction_layer>>.  When a transaction coordinator or gateway node wants to initiate a read or write against a range, it finds that range's leaseholder (using the meta ranges structure discussed in the previous section) and forwards the request to the leaseholder.

Leaseholders are assigned using the Raft protocol, which we will discuss in <<cockroachDB_replication_layer>>.

==== Range Splits

CockroachDB will attempt to keep a ((("distribution layer", "range splits", id="dstyrgp")))((("range splits", id="rgsplt")))range at less than 512 MB. When a range exceeds that size, the range will be split into two smaller contiguous ranges.

Ranges can also be split if they exceed a load threshold.  If the parameter +kv.range_split.by_load.enabled+ is true and the number of queries per second to the range exceeds the value of +kv.range_split.load_qps_threshold+, then a range may be split even if it is below the normal size threshold for range splitting.   Other factors will determine if a split actually occurs, including whether the resulting split would actually split the load between the two new ranges and the impact on queries that might now have to span the new ranges.

When splitting based on load, the two new ranges might not be of equal sizes.  By default, the range will be split at the point at which the load on the two new ranges will be roughly equal. <<Figure02-14>> illustrates a basic range split when an insert causes a range to exceed the 512 MB threshold. Two ranges are created as a consequence.
 
[[Figure02-14]] 
.Range splits
image::images/cdb2_0214.png[Range Splits]

Ranges can also be split manually using the +SPLIT AT+ clause of the +ALTER TABLE+ and +ALTER INDEX+ statements. 

Ranges can be merged as well.  If `DELETE` statements remove data from ranges and the range falls below a size ((("distribution layer", "range splits", startref="dstyrgp")))((("range splits", startref="rgsplt")))threshold, CockroachDB may merge the range with a neighboring range.


[#multiregion-distribution]
==== Multiregion Distribution

Geo-partitioning allows data to be located ((("distribution layer", "multiregion distribution")))((("geo-partitioning")))((("distribution layer", "geo-partitioning")))((("partitioning", "geo-partitioning")))within a specific geographic region.  This might be desirable from a performance point of view—reducing latencies for queries ((("latency", "distribution layer and")))((("distribution layer", "latencies")))from a region about that region—or from a data sovereignty perspective—keeping data within a specific geographic region for legal or regulatory reasons.
CockroachDB supports a multiregion configuration that controls how data should be distributed across regions.  The following core concepts are relevant:

* _Cluster regions_ are geographic regions ((("cluster regions")))((("multiregion distribution")))that a user specifies at node
start time.
* _Regions_ may have multiple zones.
* _Super Regions_ allow for data domiciling and contain one or more regions.
* Databases within the cluster are assigned to one or more regions: one
of these regions is the _primary_ region.
* Tables within a database ((("locality rules")))may have specific _locality rules_ (global,
regional by table, regional by row), which determine how its data will
be distributed across zones.
* _Survival goals_ dictate how many simultaneous ((("survival goals")))failures a database can
survive.

With the _zone-level survival goal_, the database will remain fully ((("zone-level survival goal")))available for reads and writes, even if a zone goes down. However, the database may not remain fully available if multiple zones fail in the same region. Surviving zone failures is the default setting for multiregion databases.

The _region-level survival goal_ has ((("region-level survival goals")))the property that the database will remain fully available for reads and writes, even if an entire region goes down.  This, of course, means that copies of data will need to be maintained in other regions, magnifying write time.

By default, all tables in a ((("tables", "regional tables")))((("regional tables")))multiregion database are _regional tables_—that is, CockroachDB optimizes access to the table's data from a single region (by default, the database's primary region).
_Regional by row_ tables provide low-latency reads and writes for one or more rows of a table from a single region. Different rows in the table can be optimized for access from different regions.

_Global tables_ are optimized for low-latency ((("global tables")))reads from all regions.

[[cockroachDB_replication_layer]]
=== The CockroachDB Replication Layer

High availability requires that data ((("replication layer")))((("high availability", "replication layer")))((("high availability")))not be lost or made unavailable should a node fail.  This, of course, requires that multiple copies of data be maintained.  

The two most commonly used high-availability designs are:

Active-passive:: A single node is a "primary" or "active" node ((("replication layer", "active-passive design")))((("high availability", "replication layer", "active-passive design")))((("high availability", "active-passive design")))whose changes are propagated to passive "secondary" or "passive" nodes.

Active-active:: All nodes run identical ((("replication layer", "active-active design")))((("high availability", "replication layer", "active-active design")))((("high availability", "active-active design")))services.  Typically, active-active database systems are of the "eventually consistent" variety.  Since there is no "primary," conflicting updates can be processed by different nodes.  These will need to be resolved, possibly by discarding one of the conflicting updates.


CockroachDB implements a _distributed consensus_ mechanism ((("distributed consensus")))that is called multi-active.  Like active-active, all replicas can handle traffic, but for an ((("replication layer", "multi-active design")))((("high availability", "replication layer", "multi-active design")))((("high availability", "multi-active design")))update to be accepted, it must be confirmed by a majority of voting replicas.

Not all replicas necessarily get a vote.  Nonvoting replicas are useful in globally distributed systems since they allow for low latency reads in remote regions without requiring that region to participate in consensus during writes.  This concept is discussed in more detail in <<Ch11_Multiregion_deployment>>.

This architecture ensures that there is no data loss in the event of a node failure, and the system remains available, providing at least a majority of nodes remain active. 

CockroachDB implements replication at the range level:  each range is replicated independently of other ranges.  At any given moment, a single node is responsible for changes to a single range, but there is no overall "primary" node within the cluster. 

==== Raft

CockroachDB employs the ((("distribution layer", "Raft", id="dsylrf")))((("Raft protocol", id="rfptoc")))widely used https://cockroa.ch/3x1fR8y[_Raft protocol_] as its distributed consensus mechanism.   In CockroachDB, each range is a distinct Raft group—the consensus for each range is determined independently of other ranges.

In Raft and in most distributed consensus mechanisms, we need a minimum of three nodes.  This is because a majority of nodes (a quorum) must always agree on the state.  In the event of a network partition, only the side of the partition with the majority of nodes can continue.

In a Raft group, one of the nodes is elected as leader by a majority of nodes in the group.  The other nodes are known as followers.  The Raft leader controls changes to the Raft group.

Changes sent to the Raft leader are written to its _Raft log_ and propagated to the followers.  When a majority of nodes accept the change, then the change is committed by the leader.  Note that in CockroachDB, each range has its own Raft log because every range is replicated separately.

Leader elections occur regularly or may be triggered when a node fails to receive a heartbeat message from the leader.   In the latter case, a follower who cannot communicate with the leader will declare itself a candidate and initiate an election.   Raft includes a set of safety rules that prevent any data loss during the election process.  In particular, a candidate cannot win an election unless its log contains all committed entries. 

Nodes that are temporarily disconnected from the cluster can be sent to relevant sections of the Raft log to resynchronize or—if necessary—a point-in-time snapshot of ((("distribution layer", "Raft", startref="dsylrf")))((("Raft protocol", startref="rfptoc")))the state followed by a catch-up via Raft logs.

==== Raft and Leaseholders

The CockroachDB leaseholder and the ((("distribution layer", "Raft", "leaseholders")))((("Raft protocol", "leaseholders")))((("leaseholder nodes", "Raft protocol")))Raft leader responsibilities serve similar purposes.  The leaseholder controls access to a range for the purposes of transactional integrity and isolation, while the Raft leader controls access to a range for the purposes of replication and data safety.

The leaseholder is the only node that can propose writes to the Raft leader.  CockroachDB will attempt to elect a leaseholder who is also the Raft leader so that these communications can be streamlined.  The leaseholder serves all writes and most reads, so it is able to maintain the in-memory data structures necessary to mediate read/write conflicts for the transaction layer.

==== Closed Timestamps and Follower Reads

Periodically the leaseholder ((("distribution layer", "timestamps", id="dsytmmp")))((("timestamps", "closed", id="tmmpcls")))will "close" a timestamp in the recent past, which guarantees that no new writes with lower timestamps will be accepted.

This mechanism also allows for _follower reads_.   Normally, reads have to be serviced by a replica's leaseholder. This can be slow ((("distribution layer", "follower reads")))((("follower reads")))since the leaseholder may be geographically distant from the gateway node that is issuing the query.  A follower read is a read taken from the closest replica, regardless of the replica's leaseholder status. This can result in much better latency in geo-distributed, multiregion deployments.

If a query uses the +AS OF SYSTEM TIME+ clause, then the gatekeeper forwards the request to the closest node that contains a replica of the data—whether it be a follower or the leaseholder.  The timestamp provided in the query  (i.e., the `AS OF SYSTEM TIME` value) must be less than or equal to the node's closed timestamp. This allows followers to service consistent reads in the recent past (i.e., several seconds ago).

Global tables in a multiregion database ((("nonblocking transactions")))((("transactions", "nonblocking transactions")))use a special variation of the transaction protocol called _nonblocking transactions_ that is optimized for reads (from any replica) at the expense of writes. Writes to tables in this mode are assigned timestamps in the future, and timestamps in the future may be closed. This makes it possible for followers to serve ((("distribution layer", "timestamps", startref="dsytmmp")))((("timestamps", "closed", startref="tmmpcls")))consistent reads at the present time.


=== The CockroachDB Storage Layer

We touched upon the logical structure of the KV store earlier in the chapter when we discussed the store. However, we have not yet looked at the physical implementation of the KV storage engine.

Since CockroachDB v20.2, CockroachDB has ((("storage", "Pebble storage engine")))((("Pebble storage engine")))used the Pebble storage engine—an open source KV store inspired by the LevelDB and RocksDB storage engines.   Pebble is primarily maintained by the CockroachDB team and is optimized specifically for CockroachDB use cases.  Older versions of CockroachDB use the RocksDB storage engine.

Let's look under the hood of the Pebble storage engine so that we can fully appreciate how CockroachDB stores and manipulates data at its foundational layer.

==== Log-Structured Merge Trees

Pebble implements the log-structured merge (LSM) tree ((("storage layer", "LSM (log-structured merge)")))((("LSM (log-structured merge)")))((("log-structured merge", see="LSM")))architecture.   LSM is a widely implemented and battle-tested architecture that seeks to optimize storage and support extremely high insert rates, while still supporting efficient random read access.

The simplest possible LSM tree consists of two indexed "trees:"

* An in-memory tree that is the ((("in-memory trees")))((("LSM (log-structured merge)", "in-memory trees")))recipient of all new record inserts—the _MemTable_.

* A number of on-disk trees ((("on-disk trees")))((("LSM (log-structured merge)", "on-disk trees")))((("SSTables (sorted strings tables)")))((("storage layer", "SSTables (sorted strings tables)")))((("sorted strings tables", see="SSTables")))represent copies of in-memory trees that have been flushed to disk. These are referred to as _sorted strings tables_ (SSTables).

SSTables exist at multiple levels, numbered L0 to L6 (L6 is also called the base level). L0 contains an unordered set of SSTables, each of which is simply a copy of an in-memory MemTable that has been flushed to disk. Periodically, SSTables are compacted into larger consolidated stores in the lower levels. In levels other than L0, SSTables are ordered and nonoverlapping so that only one SSTable per level could possibly hold a given key.

SSTables are internally sorted and indexed, so lookups within an SSTable are fast. 

The basic LSM architecture ensures ((("LSM (log-structured merge)", "WAL (write-ahead log)")))((("WAL (write-ahead log)")))((("write-ahead log (WAL)")))that writes are always fast since they primarily operate at memory speed, although there is often also a sequential _write-ahead log_ (WAL) on disk. The transfer to on-disk SSTables is also fast since it occurs in [.keep-together]#append-only# batches using fast sequential writes. Reads occur either from the in-memory tree or from the disk tree; in either case, reads are facilitated by an index and are relatively swift.

Of course, if a node fails while data is in the in-memory store, then it could be lost.  For this reason, database implementations of the LSM pattern include a WAL that persists transactions to disk.  The WAL is written via fast sequential writes.

<<Figure02-15>> illustrates LSM writes.  Writes from higher CockroachDB layers are first applied to the WAL (1) and then to the MemTable (2).  Once the MemTable reaches a certain size, it is flushed to disk to create a new SSTable (3).  Once the flush completes, WAL records may be purged (4). Multiple SSTables are routinely merged (compacted) into larger SSTables (5).

 
[[Figure02-15]] 
.LSM writes
image::images/cdb2_0215.png[LSM writes]

The compaction process results in multiple "levels"—Level 0 (L0) contains the uncompacted data.  Each compaction creates a file at a deeper level—up to 7 levels (L0–L6) are typical.


==== SSTables and Bloom Filters 

Each SSTable is indexed.   However, there may ((("SSTables (sorted strings tables)", "Bloom filters", id="ssssblf")))((("storage layer", "SSTables (sorted strings tables)", "Bloom filters", id="sglyssbl")))((("Bloom filters", id="blfltr")))be many SSTables on disk, and this creates a multiplier effect on index lookups because we might theoretically have to examine every index for every SSTable to find our desired row.

To reduce the overhead of multiple index lookups, _Bloom filters_ are used to reduce the number of lookups that must be performed.    A Bloom filter is a compact and quick-to-maintain structure that can quickly tell you if a given SSTable "might" contain a value.  CockroachDB uses Bloom filters to quickly determine which SSTables have a version of a key.  Bloom filters are compact enough to fit in memory and are quick to navigate. However, to achieve this compression, Bloom filters are "fuzzy" and may return false positives.  If you get a positive result from a Bloom filter, it means only that the file _may_ contain the value.  However, the Bloom filter will never incorrectly advise you that a value is not present.  So, if a Bloom filter tells us that a key is not included in a specific SSTable, then we can safely omit that SSTable from our lookup.

<<Figure02-16>> shows the read pattern for an LSM. A database request first reads from the MemTable (1). If the required value is not found, it will consult the Bloom filters for all SSTables in L0 (2).  If the Bloom filter indicates that no matching value is present, it will examine the SSTable in each subsequent level that covers the given key (3).  If the Bloom filter indicates a matching KV may be present in the SSTable, then the process will use the SSTable index (4) to search for the value within the SSTable (5).  Once a matching value is found, no ((("SSTables (sorted strings tables)", "Bloom filters", startref="ssssblf")))((("storage layer", "SSTables (sorted strings tables)", "Bloom filters", startref="sglyssbl")))((("Bloom filters", startref="blfltr")))older SSTables need to be examined.
 
[[Figure02-16]] 
.LSM reads
image::images/cdb2_0216.png[LSM Reads]

==== Deletes and Updates

SSTables are immutable—once the MemTable is flushed to disk and becomes an SSTable, no further modifications ((("SSTables (sorted strings tables)", "updates")))((("storage layer", "SSTables (sorted strings tables)", "updates")))to the SSTable can be performed. If a value is modified repeatedly over a period of time, the modifications will build up across multiple SSTables.  When retrieving a value, the system will read SSTables from youngest to oldest to find the most recent value for a key. Therefore, to update a value, we only need to insert the new value since the older values will not be examined when a newer version exists.

Deletions are implemented by writing tombstone markers into the MemTable, which eventually propagate to SSTables.   Once a tombstone marker for a row is encountered, the system stops examining older entries and reports "not found" to the application.

As SSTables multiply, read performance and storage will degrade as the number of Bloom filters, indexes, and obsolete values increases.   During compaction, rows that are fragmented across multiple SSTables will be consolidated and deleted rows removed.  Tombstones are retained until they are compacted to the base level, L6.

==== Multiversion Concurrency Control

We introduced MVCC as a logical element of the transaction layer in <<MVCC_principles>>. CockroachDB encodes the MVCC timestamp ((("storage layer", "MVCC")))((("MVCC (multiversion concurrency control)", "storage layer")))into each key so that multiple MVCC versions of a key are stored as distinct keys within Pebble.  However, the Bloom filters that we introduced previously exclude the MVCC timestamp so that a query does not need to know the exact timestamp to look up a record.

CockroachDB removes records older than the configuration variable +gc.ttlseconds+, but will not remove any records covered by _protected timestamps_.  Protected timestamps are created by long-running jobs such as backups, which need to be able to obtain a consistent view of data.

==== The Block Cache

Pebble implements a block cache ((("storage layer", "block cache")))((("block cache")))providing fast access to frequently accessed data items.  This block cache is separate from the in-memory indexes,  Bloom filters, and MemTables.  The block cache operates on a least recently used (LRU) basis—when a new data entry is added to the cache, the entry that was least recently accessed will be evicted from the cache.

Reading from the block cache bypasses the need to scan multiple SSTables and associated Bloom filters. We'll speak more about the cache in <<Ch14_Administration_and_Troubleshooting>> when we discuss cluster optimization.

=== Summary

In this chapter, we've given you an overview of the essential architectural elements of CockroachDB. Although having a strong grasp of the CockroachDB architecture is advantageous when performing advanced systems optimization or configuration, it's by no means a prerequisite for working with a CockroachDB system.   CockroachDB includes many sophisticated design elements, but its internal complexity is not [.keep-together]#reflected# in its UI—you can happily develop a CockroachDB application without mastering the architectural concepts in this chapter.

At a cluster level, a CockroachDB deployment consists of three or more symmetrical nodes, each of which carries a complete copy of the CockroachDB software stack and each of which can service any database client requests.  Data in a CockroachDB table is broken up into ranges of 512 MB in size and distributed across the nodes of the cluster.  Each range is replicated at least three times.

The CockroachDB software stack consists of five major layers:

* The SQL layer accepts SQL requests in the PostgreSQL wire protocol.  It parses and optimizes the SQL requests and translates the requests into KV operations that can be processed by lower layers.

* The transaction layer is responsible for ensuring ACID transactions and transaction isolation. It ensures that transactions see a consistent view of data and that modifications occur as if they had been executed one at a time.

* The distribution layer is responsible for the partitioning of data into ranges and the distribution of those ranges across the cluster.  It is responsible for managing Range leases and assigning leaseholders.

* The replication layer ensures that data is correctly replicated across the cluster to allow high availability in the event of a node failure.  It implements a distributed consensus mechanism to ensure that all nodes agree on the current state of any data item.

* The storage layer is responsible for the persistence of data to local disk and the processing of low-level queries and updates on that data.

In the next chapter, we'll gleefully abandon the complexities and sophisticated CockroachDB architecture and focus on the far simpler task of getting started with the CockroachDB system. 


 







